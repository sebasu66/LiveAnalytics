


# Navigation Flow Visualizer - New React Architecture

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Google Cloud Service Account JSON Key with:
  - BigQuery Data Viewer
  - BigQuery Job User
  - Google Analytics Viewer

### Running the Application

1. **Start the Backend** (Terminal 1):
```bash
npm start
# Runs on http://localhost:3000
```

2. **Start the Frontend** (Terminal 2):
```bash
cd client
npm run dev
# Runs on http://localhost:5173
```

3. **Open Browser**: Navigate to `http://localhost:5173`

## ğŸ“ Project Structure

```
live analytics/
â”œâ”€â”€ server.js                 # Express backend with GA4/BigQuery integration
â”œâ”€â”€ client/                   # React + TypeScript + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ KeyUpload.tsx        # Service Account upload UI
â”‚   â”‚   â”‚   â”œâ”€â”€ PropertySelector.tsx # GA4 property selection
â”‚   â”‚   â”‚   â””â”€â”€ SankeyCanvas.tsx     # Three.js visualization
â”‚   â”‚   â”œâ”€â”€ App.tsx           # Main app with workflow orchestration
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â””â”€â”€ vite.config.ts        # Proxy configuration
â”œâ”€â”€ js/                       # Legacy Vanilla JS (still functional)
â”œâ”€â”€ migration_plan.md         # Step-by-step migration guide
â””â”€â”€ data_contract.md          # API schemas
```

## ğŸ”„ Application Flow

### Step 1: Upload Service Account Key
- User uploads JSON key file
- Backend validates and detects:
  - Available BigQuery datasets
  - Accessible GA4 properties
- Returns temporary token (1-hour TTL)

### Step 2: Select Data Source
- User selects GA4 property
- User selects BigQuery dataset
- Frontend triggers historical data job

### Step 3: Visualization
- Backend queries BigQuery for last 30 days
- Transforms data into graph format (nodes + edges)
- Frontend renders with Three.js particles
- Real-time stats overlay

## ğŸ”Œ API Endpoints

### `POST /api/upload-key`
Upload and validate Service Account JSON key.

**Request**: `multipart/form-data` with `keyFile`

**Response**:
```json
{
  "status": "ok",
  "token": "abc123...",
  "projectId": "my-project",
  "bqDatasets": [...],
  "ga4Properties": [...]
}
```

### `POST /api/start-historical-job`
Fetch historical navigation data from BigQuery.

**Request**:
```json
{
  "token": "abc123...",
  "propertyId": "123456",
  "startDate": "2025-10-27",
  "endDate": "2025-11-26"
}
```

**Response**:
```json
{
  "status": "completed",
  "data": {
    "nodes": [...],
    "edges": [...]
  }
}
```

## ğŸ¨ Tech Stack

### Backend
- **Express.js** - REST API
- **Google Cloud SDK** - BigQuery & GA4 APIs
- **Multer** - File upload handling
- **Crypto** - Token generation

### Frontend
- **React 18** - UI framework
- **TypeScript** - Type safety
- **Vite** - Build tool & dev server
- **Three.js** - WebGL 3D visualization
- **Axios** - HTTP client

## ğŸ” Security

- Service Account keys stored in **memory only** (never on disk)
- Temporary tokens expire after **1 hour**
- Keys encrypted with Node.js `crypto` module
- CORS enabled for localhost development

## ğŸ“Š Data Flow

```
User â†’ Upload Key â†’ Backend validates â†’ Detect resources
                                      â†“
User â†’ Select Property/Dataset â†’ Backend queries BigQuery
                                      â†“
                            Transform to graph format
                                      â†“
                            Frontend renders with Three.js
```

## ğŸš§ Migration Status

âœ… **Phase 0**: Preparation (migration plan, data contracts)  
âœ… **Phase 1**: Auth & Infra (upload-key endpoint)  
âœ… **Phase 3**: Frontend Scaffold (React + Vite)  
âœ… **Phase 2 (Partial)**: Historical pipeline (basic BigQuery query)  
â³ **Phase 4**: Live data polling (5-min intervals)  
â³ **Phase 5**: LOD/Zoom & node details  
â³ **Phase 6**: AI analyst module  

## ğŸ”® Next Steps

1. **Enhance BigQuery Queries**: Build complete path analysis (acquisition â†’ landing â†’ product â†’ checkout)
2. **Live Polling Worker**: Implement 5-minute GA4 Realtime polling
3. **WebSocket/SSE**: Stream live updates to frontend
4. **Particle Animation**: Animate particles along paths
5. **LOD System**: Multi-resolution node rendering on zoom
6. **AI Insights**: Anomaly detection and automated analysis

## ğŸ› Troubleshooting

**Port 3000 already in use?**
```bash
# Windows
netstat -ano | findstr :3000
taskkill /F /PID <PID>
```

**Frontend can't reach backend?**
- Check `client/vite.config.ts` proxy is set to `http://localhost:3000`
- Ensure both servers are running

**BigQuery errors?**
- Verify Service Account has correct permissions
- Check dataset naming convention: `analytics_<propertyId>`
- Ensure GA4 â†’ BigQuery export is configured

## ğŸ“ Legacy vs New

| Feature | Legacy (Vanilla JS) | New (React) |
|---------|-------------------|-------------|
| **UI** | Canvas 2D | Three.js WebGL |
| **Auth** | Static config file | Dynamic key upload |
| **Data** | Hardcoded property | Multi-property support |
| **State** | Global variables | React hooks |
| **Build** | None | Vite (HMR) |

Both versions are functional and can run simultaneously!
